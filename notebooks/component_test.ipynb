{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbf325c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported 'calculate_delta_parameters' using sys.path!\n",
      "\n",
      "Delta for 'linear1.weight':\n",
      " tensor([[ 0.3744,  0.5441,  0.3926,  0.1149,  0.0101,  0.2010,  0.0745,  0.3978,\n",
      "          0.1596, -0.0949],\n",
      "        [-0.1606,  0.5843,  0.3371, -0.0691, -0.2148,  0.1667,  0.6730,  0.0601,\n",
      "         -0.1582, -0.3652],\n",
      "        [ 0.2169, -0.0409, -0.1358,  0.3418, -0.3873,  0.1429, -0.1740,  0.4876,\n",
      "          0.5308,  0.5774],\n",
      "        [ 0.5267,  0.0827,  0.3377,  0.4496,  0.1403,  0.1686,  0.0452,  0.2670,\n",
      "         -0.3919, -0.3605],\n",
      "        [ 0.0947,  0.6304, -0.1462, -0.3253,  0.0234, -0.0646,  0.0976,  0.4801,\n",
      "          0.3535,  0.3292],\n",
      "        [-0.1551, -0.0329,  0.1266, -0.2974, -0.2166, -0.0211,  0.4573,  0.3636,\n",
      "          0.1428,  0.3398],\n",
      "        [ 0.5905,  0.4212,  0.1720,  0.5191, -0.1907,  0.1776, -0.1384,  0.3769,\n",
      "         -0.0745,  0.2978],\n",
      "        [ 0.2325,  0.3011, -0.1855, -0.0198, -0.2593,  0.0661,  0.5228,  0.6741,\n",
      "          0.5039,  0.0554],\n",
      "        [-0.2057,  0.0921,  0.4214,  0.0527, -0.0267, -0.0295,  0.0144, -0.2220,\n",
      "          0.2431,  0.0115],\n",
      "        [ 0.3371, -0.1506,  0.4283,  0.3929,  0.2285,  0.1343,  0.0061,  0.1640,\n",
      "         -0.2447,  0.0891],\n",
      "        [-0.1662,  0.3099,  0.6843,  0.2035,  0.1958,  0.4193, -0.4463, -0.0117,\n",
      "         -0.1222,  0.2361],\n",
      "        [ 0.1577, -0.0723, -0.1752, -0.3828, -0.0636, -0.2962,  0.2253,  0.3825,\n",
      "         -0.2672, -0.0671],\n",
      "        [ 0.1747,  0.1899, -0.1132,  0.5417, -0.4503, -0.0759,  0.3207,  0.3629,\n",
      "          0.1878,  0.1837],\n",
      "        [ 0.4899, -0.1928,  0.5342,  0.4364,  0.3049, -0.3298,  0.1901, -0.2464,\n",
      "          0.0789, -0.0855],\n",
      "        [ 0.2964,  0.4854, -0.5078,  0.2608,  0.4835,  0.1065,  0.4084, -0.3974,\n",
      "         -0.3018,  0.3427],\n",
      "        [-0.2568, -0.3285,  0.0815, -0.2638,  0.0675,  0.1761,  0.3851,  0.0950,\n",
      "          0.0733,  0.1037],\n",
      "        [-0.0824, -0.0759,  0.0921,  0.0952, -0.0591,  0.0577,  0.4535,  0.1476,\n",
      "         -0.4149,  0.3647],\n",
      "        [ 0.0422,  0.3034, -0.3283,  0.0564,  0.3501,  0.3042,  0.1666,  0.6624,\n",
      "          0.4792,  0.6893],\n",
      "        [ 0.2031,  0.0969, -0.0502,  0.3107,  0.1314,  0.2006, -0.0677, -0.0854,\n",
      "          0.3676,  0.2305],\n",
      "        [-0.2364,  0.2931,  0.0955,  0.0807,  0.0591,  0.1888, -0.1544, -0.3104,\n",
      "          0.3681, -0.3648]])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the absolute path to the project's root directory and navigate from there.\n",
    "# This assumes the notebook is in the 'notebooks' folder.\n",
    "# os.path.abspath(__file__) works in .py files, but in notebooks we use os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Add the 'src' directory to Python's path\n",
    "src_path = os.path.join(project_root, 'src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "# Now, you can import your modules from the 'src' directory\n",
    "import torch\n",
    "from utils import calculate_delta_parameters\n",
    "\n",
    "# --- Example Usage ---\n",
    "print(\"Successfully imported 'calculate_delta_parameters' using sys.path!\")\n",
    "\n",
    "# (The rest of the example code remains the same)\n",
    "class SimpleModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = torch.nn.Linear(10, 20)\n",
    "    def forward(self, x):\n",
    "        return self.linear1(x)\n",
    "\n",
    "pretrained_model = SimpleModel()\n",
    "finetuned_model = SimpleModel()\n",
    "with torch.no_grad():\n",
    "    finetuned_model.linear1.weight += 0.1\n",
    "\n",
    "delta_params = calculate_delta_parameters(pretrained_model, finetuned_model)\n",
    "print(\"\\nDelta for 'linear1.weight':\\n\", delta_params['linear1.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0ab7041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor shape: torch.Size([20, 10])\n",
      "Patch size: 4x4\n",
      "Resulting patches tensor shape: torch.Size([15, 4, 4])\n",
      "The first patch:\n",
      " tensor([[ 0.3744,  0.5441,  0.3926,  0.1149],\n",
      "        [-0.1606,  0.5843,  0.3371, -0.0691],\n",
      "        [ 0.2169, -0.0409, -0.1358,  0.3418],\n",
      "        [ 0.5267,  0.0827,  0.3377,  0.4496]])\n"
     ]
    }
   ],
   "source": [
    "# Import the new function from our compression module\n",
    "from core.compression import tensor_to_patches\n",
    "\n",
    "# --- Example Usage for Patchlization ---\n",
    "\n",
    "# Let's take the delta tensor of one layer\n",
    "layer_delta = delta_params['linear1.weight']\n",
    "print(f\"Original tensor shape: {layer_delta.shape}\")\n",
    "\n",
    "# Define a patch size\n",
    "# In the paper, they use sizes like 8, 16, 32, etc.\n",
    "# For our small example, let's use a smaller size.\n",
    "p_size = 4 \n",
    "\n",
    "# Convert the tensor to patches\n",
    "patches_tensor = tensor_to_patches(layer_delta, patch_size=p_size)\n",
    "\n",
    "print(f\"Patch size: {p_size}x{p_size}\")\n",
    "print(f\"Resulting patches tensor shape: {patches_tensor.shape}\")\n",
    "print(f\"The first patch:\\n {patches_tensor[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44b27722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of the importance scores tensor: torch.Size([15])\n",
      "Number of scores matches number of patches: True\n",
      "First 5 importance scores:\n",
      " tensor([1.3688, 1.1379, 1.0448, 1.2914, 1.2891])\n"
     ]
    }
   ],
   "source": [
    "# Import the new function as well\n",
    "from core.compression import tensor_to_patches, calculate_importance_scores\n",
    "\n",
    "# --- Example Usage for Importance Assessment ---\n",
    "\n",
    "# We use the 'patches_tensor' from the previous step\n",
    "importance_scores = calculate_importance_scores(patches_tensor)\n",
    "\n",
    "print(f\"\\nShape of the importance scores tensor: {importance_scores.shape}\")\n",
    "print(f\"Number of scores matches number of patches: {importance_scores.shape[0] == patches_tensor.shape[0]}\")\n",
    "print(f\"First 5 importance scores:\\n {importance_scores[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd56c4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of the bit allocation tensor: torch.Size([15])\n",
      "Total patches: 15\n",
      "Patches assigned 2 bits: 8 (~53%)\n",
      "Patches assigned 0 bits: 7 (~47%)\n"
     ]
    }
   ],
   "source": [
    "# Import the new function\n",
    "from core.compression import tensor_to_patches, calculate_importance_scores, allocate_bit_widths\n",
    "\n",
    "# --- Example Usage for Bit-width Allocation ---\n",
    "\n",
    "# Define the allocation strategy.\n",
    "# The paper uses a 50% 2-bit and 50% 0-bit (sparsification) setup[cite: 273].\n",
    "# This is equivalent to a 1-bit compression ratio[cite: 273].\n",
    "bit_strategy = [(2, 0.5), (0, 0.5)]\n",
    "\n",
    "# Allocate bit-widths based on the importance scores\n",
    "allocated_bits = allocate_bit_widths(importance_scores, bit_strategy)\n",
    "\n",
    "print(f\"\\nShape of the bit allocation tensor: {allocated_bits.shape}\")\n",
    "\n",
    "# Verification\n",
    "num_2_bits = torch.sum(allocated_bits == 2).item()\n",
    "num_0_bits = torch.sum(allocated_bits == 0).item()\n",
    "total_patches = len(allocated_bits)\n",
    "\n",
    "print(f\"Total patches: {total_patches}\")\n",
    "print(f\"Patches assigned 2 bits: {num_2_bits} (~{num_2_bits/total_patches:.0%})\")\n",
    "print(f\"Patches assigned 0 bits: {num_0_bits} (~{num_0_bits/total_patches:.0%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec294317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Compression Results ---\n",
      "Number of compressed patches: 15\n",
      "Shape of the first compressed patch: torch.Size([4, 4])\n",
      "Data type of compressed patch: torch.int8\n",
      "\n",
      "Shape of min values tensor: torch.Size([15])\n",
      "Shape of max values tensor: torch.Size([15])\n",
      "\n",
      "Example of a 2-bit quantized patch (index 0):\n",
      "tensor([[3, 1, 1, 1],\n",
      "        [1, 1, 0, 1],\n",
      "        [2, 1, 1, 2],\n",
      "        [1, 1, 2, 1]], dtype=torch.int8)\n",
      "Its min/max range: -0.5830 / 0.9741\n",
      "\n",
      "Example of a 0-bit quantized patch (index 2):\n",
      "tensor([[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]], dtype=torch.int8)\n",
      "Its min/max range (should be the same): -0.0064 / -0.0064\n"
     ]
    }
   ],
   "source": [
    "# Import the new function\n",
    "from core.compression import tensor_to_patches, calculate_importance_scores, allocate_bit_widths, dct_and_quantize_patches\n",
    "\n",
    "# --- Example Usage for DCT and Quantization ---\n",
    "\n",
    "# We use the 'patches_tensor' and 'allocated_bits' from previous steps.\n",
    "compressed_data, min_values, max_values = dct_and_quantize_patches(patches_tensor, allocated_bits)\n",
    "\n",
    "print(\"\\n--- Compression Results ---\")\n",
    "print(f\"Number of compressed patches: {len(compressed_data)}\")\n",
    "print(f\"Shape of the first compressed patch: {compressed_data[0].shape}\")\n",
    "print(f\"Data type of compressed patch: {compressed_data[0].dtype}\")\n",
    "\n",
    "print(f\"\\nShape of min values tensor: {min_values.shape}\")\n",
    "print(f\"Shape of max values tensor: {max_values.shape}\")\n",
    "\n",
    "# Let's inspect a 2-bit patch vs a 0-bit patch\n",
    "patch_2bit_index = (allocated_bits == 2).nonzero(as_tuple=True)[0][0].item()\n",
    "patch_0bit_index = (allocated_bits == 0).nonzero(as_tuple=True)[0][0].item()\n",
    "\n",
    "print(f\"\\nExample of a 2-bit quantized patch (index {patch_2bit_index}):\\n{compressed_data[patch_2bit_index]}\")\n",
    "print(f\"Its min/max range: {min_values[patch_2bit_index].item():.4f} / {max_values[patch_2bit_index].item():.4f}\")\n",
    "\n",
    "print(f\"\\nExample of a 0-bit quantized patch (index {patch_0bit_index}):\\n{compressed_data[patch_0bit_index]}\")\n",
    "print(f\"Its min/max range (should be the same): {min_values[patch_0bit_index].item():.4f} / {max_values[patch_0bit_index].item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "403447f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Decompression Results ---\n",
      "Shape of original delta tensor: torch.Size([20, 10])\n",
      "Shape of reconstructed delta tensor: torch.Size([20, 10])\n",
      "\n",
      "Mean Squared Error (MSE) between original and reconstructed: 0.16125849\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import the new functions\n",
    "from core.decompression import dequantize_and_idct_patches, patches_to_tensor, final_rescale\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- Example Usage for Decompression ---\n",
    "\n",
    "# 1. De-quantize and apply Inverse DCT\n",
    "reconstructed_patches = dequantize_and_idct_patches(compressed_data, min_values, max_values, allocated_bits)\n",
    "\n",
    "# 2. Reassemble patches into a single tensor\n",
    "# We need the original shape of the delta tensor before padding\n",
    "original_delta_shape = layer_delta.shape\n",
    "reconstructed_delta = patches_to_tensor(reconstructed_patches, original_delta_shape, p_size)\n",
    "\n",
    "# 3. Apply the final rescaling step\n",
    "final_reconstructed_delta = final_rescale(layer_delta, reconstructed_delta)\n",
    "\n",
    "print(\"\\n--- Decompression Results ---\")\n",
    "print(f\"Shape of original delta tensor: {layer_delta.shape}\")\n",
    "print(f\"Shape of reconstructed delta tensor: {final_reconstructed_delta.shape}\")\n",
    "\n",
    "# Calculate the Mean Squared Error to measure reconstruction quality\n",
    "mse = F.mse_loss(layer_delta, final_reconstructed_delta)\n",
    "print(f\"\\nMean Squared Error (MSE) between original and reconstructed: {mse.item():.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7db1ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model compression...\n",
      "Processing layer: linear1.weight...\n",
      "Skipping layer 'linear1.bias' (tensor is not 2D, shape: torch.Size([20]))\n",
      "\n",
      "Model compression finished.\n",
      "\n",
      "--- Compressed Data Summary ---\n",
      "Compressed data contains 1 layers.\n",
      "Keys for the first compressed layer ('linear1.weight'): dict_keys(['quantized_patches', 'min_vals', 'max_vals', 'bit_allocations', 'original_shape', 'patch_size', 'original_mean_abs'])\n"
     ]
    }
   ],
   "source": [
    "# Import the main pipeline function\n",
    "# Note: To import from 'pipeline.py', we might need to add an __init__.py file\n",
    "# in the 'src' directory if it doesn't exist.\n",
    "from pipeline import compress_model\n",
    "\n",
    "# --- Example Usage for the Full Compression Pipeline ---\n",
    "\n",
    "# Define the patch size and bit strategy\n",
    "p_size = 4\n",
    "bit_strategy = [(2, 0.5), (0, 0.5)]\n",
    "\n",
    "# Use the models we created earlier\n",
    "# In a real scenario, these would be large, loaded models.\n",
    "compressed_data = compress_model(pretrained_model, finetuned_model, p_size, bit_strategy)\n",
    "\n",
    "print(\"\\n--- Compressed Data Summary ---\")\n",
    "print(f\"Compressed data contains {len(compressed_data)} layers.\")\n",
    "print(f\"Keys for the first compressed layer ('linear1.weight'): {compressed_data['linear1.weight'].keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2cd9c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model compression...\n",
      "Processing layer: linear1.weight...\n",
      "Skipping layer 'linear1.bias' (tensor is not 2D, shape: torch.Size([20]))\n",
      "\n",
      "Model compression finished.\n",
      "Starting model decompression...\n",
      "Decompressing layer: linear1.weight...\n",
      "\n",
      "Model decompression finished.\n",
      "\n",
      "--- Final Verification ---\n",
      "MSE between original fine-tuned model and reconstructed model: 0.05061575\n"
     ]
    }
   ],
   "source": [
    "# ... (previous code) ...\n",
    "import copy\n",
    "from pipeline import compress_model, decompress_model\n",
    "\n",
    "# --- Full Pipeline Example ---\n",
    "\n",
    "# 1. Compress the model (using the updated function)\n",
    "p_size = 4\n",
    "bit_strategy = [(2, 0.5), (0, 0.5)]\n",
    "compressed_data = compress_model(pretrained_model, finetuned_model, p_size, bit_strategy)\n",
    "\n",
    "# 2. Decompress the model\n",
    "reconstructed_finetuned_model = decompress_model(pretrained_model, compressed_data)\n",
    "\n",
    "# --- Final Verification ---\n",
    "# Let's compare the parameters of the original fine-tuned model and our reconstructed one.\n",
    "original_params = finetuned_model.state_dict()['linear1.weight']\n",
    "reconstructed_params = reconstructed_finetuned_model.state_dict()['linear1.weight']\n",
    "\n",
    "mse = F.mse_loss(original_params, reconstructed_params)\n",
    "print(f\"\\n--- Final Verification ---\")\n",
    "print(f\"MSE between original fine-tuned model and reconstructed model: {mse.item():.8f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "delta_dct_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
