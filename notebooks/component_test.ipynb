{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbf325c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported 'calculate_delta_parameters' using sys.path!\n",
      "\n",
      "Delta for 'linear1.weight':\n",
      " tensor([[-0.0478, -0.0470, -0.0722, -0.0315,  0.2104, -0.1691,  0.2968,  0.3209,\n",
      "          0.1526,  0.0430],\n",
      "        [ 0.5231, -0.1198,  0.3351,  0.2915,  0.4942,  0.3196, -0.4010,  0.2483,\n",
      "         -0.1163,  0.1887],\n",
      "        [ 0.2178,  0.2108,  0.5191,  0.4404, -0.0462, -0.4764,  0.3557,  0.2989,\n",
      "         -0.1637, -0.2200],\n",
      "        [ 0.0231, -0.1113,  0.1239, -0.2835, -0.3367, -0.0649,  0.0432, -0.3152,\n",
      "         -0.0645, -0.4406],\n",
      "        [ 0.6554, -0.1883,  0.5113,  0.0805,  0.0789,  0.1367, -0.0030,  0.4068,\n",
      "          0.0918,  0.1403],\n",
      "        [ 0.1779,  0.7106,  0.1371, -0.5205,  0.1100, -0.0544, -0.4055, -0.0362,\n",
      "          0.4099, -0.0933],\n",
      "        [ 0.0841,  0.5952,  0.2625,  0.5957, -0.1909,  0.2337,  0.3199, -0.3877,\n",
      "         -0.2262, -0.0243],\n",
      "        [ 0.0921,  0.2066,  0.3811,  0.2915,  0.0121,  0.2504,  0.0858,  0.0658,\n",
      "          0.5264,  0.0329],\n",
      "        [ 0.6123,  0.1868,  0.0792, -0.1679,  0.0734, -0.2942,  0.1357,  0.2634,\n",
      "          0.2043, -0.0534],\n",
      "        [-0.0404,  0.3409,  0.3118,  0.1058,  0.3742, -0.0973,  0.6605,  0.1412,\n",
      "          0.3475, -0.3366],\n",
      "        [ 0.5178, -0.2082,  0.4006,  0.3202,  0.5044, -0.1034,  0.3782,  0.3519,\n",
      "         -0.2425, -0.1272],\n",
      "        [ 0.0062, -0.4143,  0.2889,  0.1827,  0.3661, -0.1570,  0.3989,  0.0565,\n",
      "          0.3670,  0.0009],\n",
      "        [ 0.0897,  0.4787,  0.2731, -0.2311,  0.5823,  0.3702,  0.3159,  0.2476,\n",
      "          0.5197,  0.4078],\n",
      "        [ 0.0656,  0.0348,  0.0328,  0.4707, -0.2482,  0.1826,  0.4859,  0.2561,\n",
      "          0.3478, -0.3574],\n",
      "        [ 0.4453,  0.5168, -0.0400, -0.0230,  0.3368, -0.0853,  0.2287,  0.0038,\n",
      "         -0.1909,  0.1533],\n",
      "        [-0.1373,  0.4705, -0.3603,  0.3092,  0.1547,  0.1229,  0.2316, -0.0375,\n",
      "          0.1243, -0.1370],\n",
      "        [ 0.1791,  0.5404,  0.3390, -0.3531, -0.3795,  0.2165, -0.1332, -0.1179,\n",
      "          0.3854,  0.0098],\n",
      "        [ 0.2931,  0.0773,  0.3020, -0.2684,  0.2489, -0.2048,  0.2231, -0.4101,\n",
      "         -0.2978, -0.1755],\n",
      "        [ 0.0149,  0.3326, -0.1001,  0.3961, -0.1788,  0.5152,  0.2686, -0.1911,\n",
      "          0.3420, -0.1733],\n",
      "        [-0.1391,  0.4524, -0.3045, -0.1599,  0.5733,  0.3269,  0.2563,  0.3468,\n",
      "          0.4557, -0.1617]])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the absolute path to the project's root directory and navigate from there.\n",
    "# This assumes the notebook is in the 'notebooks' folder.\n",
    "# os.path.abspath(__file__) works in .py files, but in notebooks we use os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Add the 'src' directory to Python's path\n",
    "src_path = os.path.join(project_root, 'src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "# Now, you can import your modules from the 'src' directory\n",
    "import torch\n",
    "from utils import calculate_delta_parameters\n",
    "\n",
    "# --- Example Usage ---\n",
    "print(\"Successfully imported 'calculate_delta_parameters' using sys.path!\")\n",
    "\n",
    "# (The rest of the example code remains the same)\n",
    "class SimpleModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = torch.nn.Linear(10, 20)\n",
    "    def forward(self, x):\n",
    "        return self.linear1(x)\n",
    "\n",
    "pretrained_model = SimpleModel()\n",
    "finetuned_model = SimpleModel()\n",
    "with torch.no_grad():\n",
    "    finetuned_model.linear1.weight += 0.1\n",
    "\n",
    "delta_params = calculate_delta_parameters(pretrained_model, finetuned_model)\n",
    "print(\"\\nDelta for 'linear1.weight':\\n\", delta_params['linear1.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ab7041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the new function from our compression module\n",
    "from core.compression import tensor_to_patches\n",
    "\n",
    "# --- Example Usage for Patchlization ---\n",
    "\n",
    "# Let's take the delta tensor of one layer\n",
    "layer_delta = delta_params['linear1.weight']\n",
    "print(f\"Original tensor shape: {layer_delta.shape}\")\n",
    "\n",
    "# Define a patch size\n",
    "# In the paper, they use sizes like 8, 16, 32, etc.\n",
    "# For our small example, let's use a smaller size.\n",
    "p_size = 4 \n",
    "\n",
    "# Convert the tensor to patches\n",
    "patches_tensor = tensor_to_patches(layer_delta, patch_size=p_size)\n",
    "\n",
    "print(f\"Patch size: {p_size}x{p_size}\")\n",
    "print(f\"Resulting patches tensor shape: {patches_tensor.shape}\")\n",
    "print(f\"The first patch:\\n {patches_tensor[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b27722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the new function as well\n",
    "from core.compression import tensor_to_patches, calculate_importance_scores\n",
    "\n",
    "# --- Example Usage for Importance Assessment ---\n",
    "\n",
    "# We use the 'patches_tensor' from the previous step\n",
    "importance_scores = calculate_importance_scores(patches_tensor)\n",
    "\n",
    "print(f\"\\nShape of the importance scores tensor: {importance_scores.shape}\")\n",
    "print(f\"Number of scores matches number of patches: {importance_scores.shape[0] == patches_tensor.shape[0]}\")\n",
    "print(f\"First 5 importance scores:\\n {importance_scores[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd56c4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the new function\n",
    "from core.compression import tensor_to_patches, calculate_importance_scores, allocate_bit_widths\n",
    "\n",
    "# --- Example Usage for Bit-width Allocation ---\n",
    "\n",
    "# Define the allocation strategy.\n",
    "# The paper uses a 50% 2-bit and 50% 0-bit (sparsification) setup[cite: 273].\n",
    "# This is equivalent to a 1-bit compression ratio[cite: 273].\n",
    "bit_strategy = [(2, 0.5), (0, 0.5)]\n",
    "\n",
    "# Allocate bit-widths based on the importance scores\n",
    "allocated_bits = allocate_bit_widths(importance_scores, bit_strategy)\n",
    "\n",
    "print(f\"\\nShape of the bit allocation tensor: {allocated_bits.shape}\")\n",
    "\n",
    "# Verification\n",
    "num_2_bits = torch.sum(allocated_bits == 2).item()\n",
    "num_0_bits = torch.sum(allocated_bits == 0).item()\n",
    "total_patches = len(allocated_bits)\n",
    "\n",
    "print(f\"Total patches: {total_patches}\")\n",
    "print(f\"Patches assigned 2 bits: {num_2_bits} (~{num_2_bits/total_patches:.0%})\")\n",
    "print(f\"Patches assigned 0 bits: {num_0_bits} (~{num_0_bits/total_patches:.0%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec294317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the new function\n",
    "from core.compression import tensor_to_patches, calculate_importance_scores, allocate_bit_widths, dct_and_quantize_patches\n",
    "\n",
    "# --- Example Usage for DCT and Quantization ---\n",
    "\n",
    "# We use the 'patches_tensor' and 'allocated_bits' from previous steps.\n",
    "compressed_data, min_values, max_values = dct_and_quantize_patches(patches_tensor, allocated_bits)\n",
    "\n",
    "print(\"\\n--- Compression Results ---\")\n",
    "print(f\"Number of compressed patches: {len(compressed_data)}\")\n",
    "print(f\"Shape of the first compressed patch: {compressed_data[0].shape}\")\n",
    "print(f\"Data type of compressed patch: {compressed_data[0].dtype}\")\n",
    "\n",
    "print(f\"\\nShape of min values tensor: {min_values.shape}\")\n",
    "print(f\"Shape of max values tensor: {max_values.shape}\")\n",
    "\n",
    "# Let's inspect a 2-bit patch vs a 0-bit patch\n",
    "patch_2bit_index = (allocated_bits == 2).nonzero(as_tuple=True)[0][0].item()\n",
    "patch_0bit_index = (allocated_bits == 0).nonzero(as_tuple=True)[0][0].item()\n",
    "\n",
    "print(f\"\\nExample of a 2-bit quantized patch (index {patch_2bit_index}):\\n{compressed_data[patch_2bit_index]}\")\n",
    "print(f\"Its min/max range: {min_values[patch_2bit_index].item():.4f} / {max_values[patch_2bit_index].item():.4f}\")\n",
    "\n",
    "print(f\"\\nExample of a 0-bit quantized patch (index {patch_0bit_index}):\\n{compressed_data[patch_0bit_index]}\")\n",
    "print(f\"Its min/max range (should be the same): {min_values[patch_0bit_index].item():.4f} / {max_values[patch_0bit_index].item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403447f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import the new functions\n",
    "from core.decompression import dequantize_and_idct_patches, patches_to_tensor, final_rescale\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- Example Usage for Decompression ---\n",
    "\n",
    "# 1. De-quantize and apply Inverse DCT\n",
    "reconstructed_patches = dequantize_and_idct_patches(compressed_data, min_values, max_values, allocated_bits)\n",
    "\n",
    "# 2. Reassemble patches into a single tensor\n",
    "# We need the original shape of the delta tensor before padding\n",
    "original_delta_shape = layer_delta.shape\n",
    "reconstructed_delta = patches_to_tensor(reconstructed_patches, original_delta_shape, p_size)\n",
    "\n",
    "# 3. Apply the final rescaling step\n",
    "final_reconstructed_delta = final_rescale(layer_delta, reconstructed_delta)\n",
    "\n",
    "print(\"\\n--- Decompression Results ---\")\n",
    "print(f\"Shape of original delta tensor: {layer_delta.shape}\")\n",
    "print(f\"Shape of reconstructed delta tensor: {final_reconstructed_delta.shape}\")\n",
    "\n",
    "# Calculate the Mean Squared Error to measure reconstruction quality\n",
    "mse = F.mse_loss(layer_delta, final_reconstructed_delta)\n",
    "print(f\"\\nMean Squared Error (MSE) between original and reconstructed: {mse.item():.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7db1ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the main pipeline function\n",
    "# Note: To import from 'pipeline.py', we might need to add an __init__.py file\n",
    "# in the 'src' directory if it doesn't exist.\n",
    "from pipeline import compress_model\n",
    "\n",
    "# --- Example Usage for the Full Compression Pipeline ---\n",
    "\n",
    "# Define the patch size and bit strategy\n",
    "p_size = 4\n",
    "bit_strategy = [(2, 0.5), (0, 0.5)]\n",
    "\n",
    "# Use the models we created earlier\n",
    "# In a real scenario, these would be large, loaded models.\n",
    "compressed_data = compress_model(pretrained_model, finetuned_model, p_size, bit_strategy)\n",
    "\n",
    "print(\"\\n--- Compressed Data Summary ---\")\n",
    "print(f\"Compressed data contains {len(compressed_data)} layers.\")\n",
    "print(f\"Keys for the first compressed layer ('linear1.weight'): {compressed_data['linear1.weight'].keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cd9c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... (previous code) ...\n",
    "import copy\n",
    "from pipeline import compress_model, decompress_model\n",
    "\n",
    "# --- Full Pipeline Example ---\n",
    "\n",
    "# 1. Compress the model (using the updated function)\n",
    "p_size = 4\n",
    "bit_strategy = [(2, 0.5), (0, 0.5)]\n",
    "compressed_data = compress_model(pretrained_model, finetuned_model, p_size, bit_strategy)\n",
    "\n",
    "# 2. Decompress the model\n",
    "reconstructed_finetuned_model = decompress_model(pretrained_model, compressed_data)\n",
    "\n",
    "# --- Final Verification ---\n",
    "# Let's compare the parameters of the original fine-tuned model and our reconstructed one.\n",
    "original_params = finetuned_model.state_dict()['linear1.weight']\n",
    "reconstructed_params = reconstructed_finetuned_model.state_dict()['linear1.weight']\n",
    "\n",
    "mse = F.mse_loss(original_params, reconstructed_params)\n",
    "print(f\"\\n--- Final Verification ---\")\n",
    "print(f\"MSE between original fine-tuned model and reconstructed model: {mse.item():.8f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "delta_dct_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
